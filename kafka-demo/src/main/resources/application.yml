server:
  port: 8080

spring:
  profiles:
    active: dev
  application:
    name: kafka-demo
  sleuth:
    default-logging-pattern-enabled: false
    sampler:
      probability: 1.0
  kafka:
    topic: DemoKafkaTopicDev
    bootstrap-servers:
      - dev.kafka:9094
    producer:
      # 发生错误后，消息重发的次数，0 为不启用重试机制，默认值为 int 最大值
      retries: 3
      # 当有多个消息需要被发送到统一分区时，生产者会将它们放在同一批次里。该参数指定一个批次可以使用的内存大小，按字节数计算
      # batch-size: 16384
      # 生产者可以使用的总内存字节来缓冲等待发送到服务器的记录
      # buffer-memory: 33554432
      # 键的序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 值的序列化方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # acks 应答机制
      # acks=0：生产者发送数据后，不需要等待数据落盘应答。
      # acks=1：生产者发送数据后，Leader 收到数据后应答。
      # acks=all：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: -1
      properties:
        # 批量发送，延迟为 1 毫秒，启用该功能能有效减少生产者发送消息次数，从而提高并发量
        linger.ms: 1
        # 对发送的数据进行压缩，支持压缩类型：none、gzip、snappy、lz4 和 zstd
        # compression-type: "snappy"
        # 开启事务
        # transaction-id-prefix: myapp
    consumer:
      group-id: demo_kafka_test_dev
      # 是否自动提交偏移量，默认值是 true，为了避免出现重复数据和数据丢失，可以将其设置为 false，然后手动提交偏移量
      enable-auto-commit: false
      # 自动提交的时间间隔，在 Spring Boot 2.x 版本中，这里采用的值的类型为 Duration，需要符合特定的格式，例如 1S，1M，2H，5D
      auto-commit-interval: 1s
      # 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
      # latest（默认值）：在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
      # earliest：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
      # none：如果无 offset 就抛出异常
      auto-offset-reset: latest
      # 键的反序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 值的反序列化方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 这个参数允许消费者指定从 broker 读取消息时最小的 Payload 的字节数。当消费者从 broker 读取消息时，如果数据字节数小于这个阈值，broker 会等待直到有足够的数据，然后才返回给消费者。
      fetch-min-size: 1 # 默认值： 1
      # 上面的 fetch.min.bytes 参数指定了消费者读取的最小数据量，而这个参数则指定了消费者读取时最长等待时间，从而避免长时间阻塞。该参数默认值为 500ms。
      fetch-max-wait: 500
      # 这个参数控制一个 poll() 调用返回的记录数，即消费者每次批量拉取多少条数据。
      max-poll-records: 500

    listener:
      # 在监听器容器中运行的线程数，创建多少个 consumer，值必须小于等于 Kafka Topic 的分区数。
      concurrency: 1 # 建议设置为 topic 的分区数
      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # RECORD：
      # 当每一批 poll() 的数据被消费者监听器（ListenerConsumer）处理之后提交
      # BATCH：
      # 当每一批 poll() 的数据被消费者监听器（ListenerConsumer）处理之后，间隔时间大于等于 TIME 时提交
      # TIME：
      # 当每一批 poll() 的数据被消费者监听器（ListenerConsumer）处理之后，被处理的 record 数量大于等于 COUNT 时提交
      # COUNT：
      # TIME | COUNT 有一个条件满足时提交
      # COUNT_TIME：
      # 当每一批 poll() 的数据被消费者监听器（ListenerConsumer）处理之后，手动调用 Acknowledgment.acknowledge() 后提交
      # MANUAL：
      # 手动调用 Acknowledgment.acknowledge() 后立即提交，一般使用这种
      # MANUAL_IMMEDIATE：
      # listener 负责 ack，每调用一次，就立即 commit
      ack-mode: manual_immediate
      # 消费监听接口监听的主题不存在时，默认会报错
      missing-topics-fatal: false
      # 使用批量消费需要将 listener 的 type 设置为 batch，该值默认为 single
      # type: batch